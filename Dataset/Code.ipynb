{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e61f881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Dataset: 2000 rows, 11 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "df = pd.read_csv(\"unclean_data.csv\")\n",
    "\n",
    "print(f\"Loaded Dataset: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee258663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USER_ID', 'ORDER_ID', 'PURCHASE_TS', 'SHIP_TS', 'PRODUCT_NAME', 'PRODUCT_ID', 'GBP_PRICE', 'PURCHASE_PLATFORM', 'MARKETING_CHANNEL', 'ACCOUNT_CREATION_METHOD', 'CITY']\n",
      "FIX APPLIED\n",
      "['user_id', 'order_id', 'purchase_ts', 'ship_ts', 'product_name', 'product_id', 'gbp_price', 'purchase_platform', 'marketing_channel', 'account_creation_method', 'city']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Step 1: HEADER CLEANING \n",
    "# =========================\n",
    "\n",
    "print(df.columns.tolist())\n",
    "\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17cb6fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EMAIL' 'search' 'affiliate' ' direct ' 'direct' 'social' 'email'\n",
      " 'DIRECT' 'SEARCH' nan 'AFFILIATE' ' AFFILIATE ' ' email ' 'SOCIAL'\n",
      " ' affiliate ' ' SOCIAL ' ' social ' ' SEARCH ' ' DIRECT ' ' EMAIL '\n",
      " ' search ']\n",
      "['website' 'mobile_app' 'WEBSITE' 'MOBILE_APP']\n",
      "['desktop' 'mobile' 'unknown' 'UNKNOWN' 'MOBILE' nan 'DESKTOP']\n",
      "['LEEDS' 'Manchester' 'Birmingham' 'MANCHESTER' 'GLASGOW' nan 'Leicester'\n",
      " 'Leeds' 'London' 'Liverpool' 'LONDON' 'Glasgow' 'Bristol' 'Sheffield'\n",
      " 'BIRMINGHAM' 'LEICESTER' 'Nottingham' 'BRISTOL' 'Londn' 'LIVERPOOL'\n",
      " 'NOTTINGHAM' 'Glasow' 'Manchster' 'SHEFFIELD']\n",
      "FIX APPLIED\n",
      "['email' 'search' 'affiliate' 'direct' 'social' nan]\n",
      "['website' 'mobile_app']\n",
      "['desktop' 'mobile' 'unknown' nan]\n",
      "['leeds' 'manchester' 'birmingham' 'glasgow' nan 'leicester' 'london'\n",
      " 'liverpool' 'bristol' 'sheffield' 'nottingham' 'londn' 'glasow'\n",
      " 'manchster']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Step 2: CASE FORMATTING\n",
    "# =========================\n",
    "\n",
    "print(df['marketing_channel'].unique())\n",
    "print(df['purchase_platform'].unique())\n",
    "print(df['account_creation_method'].unique())\n",
    "print(df['city'].unique())\n",
    "\n",
    "df['marketing_channel'] = df['marketing_channel'].str.strip().str.lower()\n",
    "df['purchase_platform'] = df['purchase_platform'].str.strip().str.lower()\n",
    "df['account_creation_method'] = df['account_creation_method'].str.strip().str.lower()\n",
    "df['city'] = df['city'].str.strip().str.lower()\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "\n",
    "print(df['marketing_channel'].unique())\n",
    "print(df['purchase_platform'].unique())\n",
    "print(df['account_creation_method'].unique())\n",
    "print(df['city'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d15a48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leeds' 'manchester' 'birmingham' 'glasgow' nan 'leicester' 'london'\n",
      " 'liverpool' 'bristol' 'sheffield' 'nottingham' 'londn' 'glasow'\n",
      " 'manchster']\n",
      "FIX APPLIED\n",
      "['leeds' 'manchester' 'birmingham' 'glasgow' nan 'leicester' 'london'\n",
      " 'liverpool' 'bristol' 'sheffield' 'nottingham']\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Step 3: TYPOS CITY COLUMN\n",
    "# =============================\n",
    "\n",
    "print(df['city'].unique())\n",
    "\n",
    "cleanup_map = {\n",
    "    'londn':'london',\n",
    "    'glasow':'glasgow',\n",
    "    'manchster':'manchester' \n",
    "}\n",
    "\n",
    "df['city'] = df['city'].replace(cleanup_map)\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "\n",
    "print(df['city'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a104999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accessory' 'Steam Deck' 'Kindle Paperwhite' 'MacBook Air' 'iPhone 15'\n",
      " 'Smartwatch' 'Google Pixel 8' 'PS5' 'Xbox Series X' 'AirPods'\n",
      " 'Nintendo Switch']\n",
      "['24.99' '499.99' '129.99' '1199.99' '899.99' '249.99' '699.99' '479.99'\n",
      " '499.99 GBP' 'gbp 499.99' '449.99' '449.99 GBP' 'gbp 699.99' '159.99'\n",
      " '£ 449.99' '£ 249.99' '299.99' '499.99,00' '479.99,00' '£24.99' '€899.99'\n",
      " '€479.99' '249.99,00' '24.99 GBP' '£ 1199.99' '479.99 GBP' 'gbp 129.99'\n",
      " '249.99 GBP' '£ 129.99' '£449.99' '£ 499.99' '299.99 GBP' '£499.99'\n",
      " '€249.99' '€499.99' '£ 159.99' '€24.99' '299.99,00' 'gbp 24.99'\n",
      " '159.99 GBP' '£479.99' '€1199.99' '€299.99' 'gbp 449.99' 'gbp 299.99'\n",
      " '£249.99' '£129.99' '1199.99 GBP' '£899.99' '1199.99,00' '£ 699.99'\n",
      " '159.99,00' 'gbp 479.99' '449.99,00' '£1199.99' '899.99 GBP' '£ 899.99'\n",
      " '129.99,00' '699.99,00' 'gbp 1199.99' '699.99 GBP' '24.99,00' '€129.99'\n",
      " '129.99 GBP' 'gbp 249.99' '£ 299.99' '£699.99' '€699.99' '£299.99'\n",
      " 'gbp 899.99']\n",
      "FIX APPLIED\n",
      "['Accessory' 'Steam Deck' 'Kindle Paperwhite' 'MacBook Air' 'iPhone 15'\n",
      " 'Smartwatch' 'Google Pixel 8' 'PS5' 'Xbox Series X' 'AirPods'\n",
      " 'Nintendo Switch']\n",
      "[24.99 499.99 129.99 1199.99 899.99 249.99 699.99 479.99 449.99 159.99\n",
      " 299.99]\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Step 4: PRODUCT NAME AND PRICE MATCH \n",
    "# ====================================\n",
    "\n",
    "print(df['product_name'].unique())\n",
    "print(df['gbp_price'].unique())\n",
    "\n",
    "price_map = {\n",
    "    'Accessory': 24.99,\n",
    "    'Steam Deck': 499.99,\n",
    "    'Kindle Paperwhite': 129.99,\n",
    "    'PS5': 479.99,\n",
    "    'Google Pixel 8': 699.99,\n",
    "    'Smartwatch': 249.99,\n",
    "    'Xbox Series X': 449.99,\n",
    "    'AirPods': 159.99,\n",
    "    'Nintendo Switch': 299.99,\n",
    "    'MacBook Air': 1199.99,\n",
    "    'iPhone 15': 899.99\n",
    "}\n",
    "\n",
    "df.loc[df['product_name'].isin(price_map.keys()), 'gbp_price'] = (\n",
    "    df['product_name'].map(price_map)\n",
    ")\n",
    "\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "print(df['product_name'].unique())\n",
    "print(df['gbp_price'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4819699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype object\n",
      "FIX APPLIED\n",
      "Dtype float64\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 4: PRICE COLUMN TYPE CHANGE  \n",
    "# ================================\n",
    "\n",
    "print(\"Dtype\", df['gbp_price'].dtype)\n",
    "\n",
    "df['gbp_price'] = df['gbp_price'].astype(float)\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "\n",
    "print(\"Dtype\", df['gbp_price'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d3a8c03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11/06/2025' '23/03/2025' '24/04/2025' '02/06/2025' '22/03/2025'\n",
      " '10/04/2025' '15/02/2025' '07/05/2025' '14/06/2025' '20/01/2025']\n",
      "Dtype object\n",
      "FIX APPLIED\n",
      "<DatetimeArray>\n",
      "['2025-06-11 00:00:00', '2025-03-23 00:00:00', '2025-04-24 00:00:00',\n",
      " '2025-06-02 00:00:00', '2025-03-22 00:00:00', '2025-04-10 00:00:00',\n",
      " '2025-02-15 00:00:00', '2025-05-07 00:00:00', '2025-06-14 00:00:00',\n",
      " '2025-01-20 00:00:00']\n",
      "Length: 10, dtype: datetime64[ns]\n",
      "Dtype datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Step 5: PURCHASE DATE COLUMN TYPE CHANGE  \n",
    "# ========================================\n",
    "\n",
    "print(df['purchase_ts'].unique()[:10])\n",
    "print(\"Dtype\", df['purchase_ts'].dtype)\n",
    "\n",
    "df['purchase_ts'] = pd.to_datetime(df['purchase_ts'], format='%d/%m/%Y')\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "\n",
    "print(df['purchase_ts'].unique()[:10])\n",
    "print(\"Dtype\", df['purchase_ts'].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f9f95bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12/06/2025' '25/03/2025' '04-28-2025' '26/04/2025' '08/06/2025'\n",
      " '04-13-2025' '16/02/2025' '18/02/2025' '02-20-2025' '10/05/2025']\n",
      "Dtype object\n",
      "FIX APPLIED\n",
      "<DatetimeArray>\n",
      "['2025-12-06 00:00:00', '2025-03-25 00:00:00', '2025-04-28 00:00:00',\n",
      " '2025-04-26 00:00:00', '2025-08-06 00:00:00', '2025-04-13 00:00:00',\n",
      " '2025-02-16 00:00:00', '2025-02-18 00:00:00', '2025-02-20 00:00:00',\n",
      " '2025-10-05 00:00:00']\n",
      "Length: 10, dtype: datetime64[ns]\n",
      "Dtype datetime64[ns]\n",
      "NaT values: 0\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Step 6: SHIP DATE  FORMAT / TYPE CHANGE  \n",
    "# =======================================\n",
    "\n",
    "print(df['ship_ts'].unique()[:10])\n",
    "print(\"Dtype\", df['ship_ts'].dtype)\n",
    "\n",
    "df['ship_ts'] = df['ship_ts'].str.strip().str.replace('-', '/', regex=False)\n",
    "\n",
    "def parse_mixed_date(x): # some dates where mixed between DD/MM/YYYY & MM/DD/YYYY \n",
    "    try:\n",
    "        dt = pd.to_datetime(x, format='%m/%d/%Y')\n",
    "    except ValueError:\n",
    "        dt = pd.to_datetime(x, format='%d/%m/%Y')\n",
    "    return dt\n",
    "\n",
    "df['ship_ts'] = df['ship_ts'].apply(parse_mixed_date).dt.strftime('%d/%m/%Y')\n",
    "df['ship_ts'] = pd.to_datetime(df['ship_ts'], format='%d/%m/%Y')\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "print(df['ship_ts'].unique()[:10])\n",
    "print(\"Dtype\", df['ship_ts'].dtype)\n",
    "num_missing = df['ship_ts'].isna().sum()\n",
    "print(\"NaT values:\", num_missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d33014ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   purchase_ts    ship_ts\n",
      "39  2025-03-27 2025-01-04\n",
      "43  2025-02-24 2025-02-03\n",
      "57  2025-06-01 2025-05-06\n",
      "Total number: 108\n",
      "FIX APPLIED\n",
      "   purchase_ts    ship_ts\n",
      "39  2025-03-27 2025-04-26\n",
      "43  2025-02-24 2025-03-26\n",
      "57  2025-06-01 2025-07-01\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# Step 7: LOGICAL INTEGRITY (TIME TRAVEL)\n",
    "# =======================================\n",
    "\n",
    "time_travel_mask = df['ship_ts'] < df['purchase_ts'] \n",
    "print(df.loc[time_travel_mask,['purchase_ts','ship_ts']].head(3)) #To show if they're rows with ship_ts date before purchase_ts date\n",
    "num_time_travel = time_travel_mask.sum()\n",
    "print(\"Total number:\", num_time_travel)\n",
    "\n",
    "df.loc[time_travel_mask, 'ship_ts'] = df.loc[time_travel_mask, 'purchase_ts'] + pd.Timedelta(days=30) #changed those dates to 30 days after the purchase_ts date\n",
    "\n",
    "print(\"FIX APPLIED\")\n",
    "print(df.loc[time_travel_mask,['purchase_ts','ship_ts']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "001f49f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   user_id                  2000 non-null   object        \n",
      " 1   order_id                 2000 non-null   object        \n",
      " 2   purchase_ts              2000 non-null   datetime64[ns]\n",
      " 3   ship_ts                  1892 non-null   datetime64[ns]\n",
      " 4   product_name             2000 non-null   object        \n",
      " 5   product_id               2000 non-null   object        \n",
      " 6   gbp_price                2000 non-null   float64       \n",
      " 7   purchase_platform        2000 non-null   object        \n",
      " 8   marketing_channel        1959 non-null   object        \n",
      " 9   account_creation_method  1954 non-null   object        \n",
      " 10  city                     1963 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), object(8)\n",
      "memory usage: 172.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
